{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 与人工智能（读书笔记）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-与人工智能\" data-toc-modified-id=\"Python-与人工智能-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Python 与人工智能</a></span><ul class=\"toc-item\"><li><span><a href=\"#人工智能概述\" data-toc-modified-id=\"人工智能概述-15.1\"><span class=\"toc-item-num\">15.1&nbsp;&nbsp;</span>人工智能概述</a></span></li><li><span><a href=\"#深度学习框架简介\" data-toc-modified-id=\"深度学习框架简介-15.2\"><span class=\"toc-item-num\">15.2&nbsp;&nbsp;</span>深度学习框架简介</a></span></li><li><span><a href=\"#深度学习中的数学概念\" data-toc-modified-id=\"深度学习中的数学概念-15.3\"><span class=\"toc-item-num\">15.3&nbsp;&nbsp;</span>深度学习中的数学概念</a></span></li><li><span><a href=\"#神经网络剖析\" data-toc-modified-id=\"神经网络剖析-15.4\"><span class=\"toc-item-num\">15.4&nbsp;&nbsp;</span>神经网络剖析</a></span><ul class=\"toc-item\"><li><span><a href=\"#层:-深度学习的基础组件\" data-toc-modified-id=\"层:-深度学习的基础组件-15.4.1\"><span class=\"toc-item-num\">15.4.1&nbsp;&nbsp;</span>层: 深度学习的基础组件</a></span></li><li><span><a href=\"#模型：层构成的网络\" data-toc-modified-id=\"模型：层构成的网络-15.4.2\"><span class=\"toc-item-num\">15.4.2&nbsp;&nbsp;</span>模型：层构成的网络</a></span></li><li><span><a href=\"#损失函数和优化器：配置学习过程的关键\" data-toc-modified-id=\"损失函数和优化器：配置学习过程的关键-15.4.3\"><span class=\"toc-item-num\">15.4.3&nbsp;&nbsp;</span>损失函数和优化器：配置学习过程的关键</a></span></li></ul></li><li><span><a href=\"#典型的Keras工作流程\" data-toc-modified-id=\"典型的Keras工作流程-15.5\"><span class=\"toc-item-num\">15.5&nbsp;&nbsp;</span>典型的Keras工作流程</a></span></li><li><span><a href=\"#示例：手写数字图像识别\" data-toc-modified-id=\"示例：手写数字图像识别-15.6\"><span class=\"toc-item-num\">15.6&nbsp;&nbsp;</span>示例：手写数字图像识别</a></span></li><li><span><a href=\"#本章小结\" data-toc-modified-id=\"本章小结-15.7\"><span class=\"toc-item-num\">15.7&nbsp;&nbsp;</span>本章小结</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "人工智能诞生于20世纪50年代，随后引起了众多学科和不同专业背景的学者们以及各国政府和企业家的空前重视，目前已成为一门具有日臻完善的理论基础、日益广泛的应用领域和广泛交叉的前沿学科。伴随着社会进步和科技发展步伐，人工智能与时俱进，不断取得新的发展，并在近年来出现一股开发与应用人工智能的热潮。Python语言使用广泛，代码范例和很多，便于读者快速学习和掌握。此外，在开发实际应用程序时，可以利用其丰富的模块库缩短开发周期。基于这些原因，Python成为目前应用最为广泛的人工智能应用程序开发语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人工智能概述\n",
    "\n",
    "人工智能是一个综合领域，包括机器学习、深度学习，以及其他不涉及学习的方法。例如，早期的国际象棋程序仅包含程序员精心编写的硬编码规则，并不属于机器学习。在20世纪50年代到80现代末，符号主义人工智能（symbolic AI）是人工智能的主流范式，人们相信，只要程序员精心编写足够多的明确规则来处理知识，就可以实现与人类水平相当的人工智能。在20世纪80年代的专家系统（expert system）热潮中，这一方法的热度达到了顶峰。\n",
    "\n",
    "虽然符号主义人工智能适合解决定义明确的逻辑问题，比如下国际象棋，但它难以给出明确的规则来解决更加复杂、模糊的问题，比如图像分类、语音识别和语言翻译。于是出现了一种新的方法来替代符号主义人工智能，这就是机器学习（machine learning）。\n",
    "\n",
    "机器学习的概念来自于图灵的以下问题：对于计算机而言，除了“我们命令它做的任何事情”之外，它能否自我学习执行特定任务的方法？如果没有程序员精心编写的数据处理规则，计算机能否通过观察数据自动学会这些规则？\n",
    "\n",
    "图灵的这个问题引出了一种新的编程范式。在经典的程序设计（即符号主义人工智能的范式）中，人们输入的是规则（即程序）和需要根据这些规则进行处理的数据，系统输出的是答案。利用机器学习，人们输入的是数据和从这些数据中预期得到的答案，系统输出的是规则。这些规则可应用于新的数据，并使计算机自主生成答案。\n",
    "\n",
    "机器学习系统是训练出来的，而不是明确地用程序编写出来的。将与某个任务相关的许多实例输入机器学习系统，她会在这些示例中找到统计结构，从而最终找到 规则将任务自动化。举个例子，你想为度假照片添加标签，并且希望将这个项目任务化，那么你可以将许多人工打好标签的照片输入机器学习系统，系统将学会将照片与特定标签联系在一起的统计规则。\n",
    "\n",
    "虽然机器学习在20世纪90年代才开始蓬勃发展，但它迅速成为人工智能最受欢迎且最成功的分支领域。这一发展的驱动力来自于速度更快的硬件与更大的数据集。机器学习与数量统计密切相关，但二者在几个重要方面有所不同。不同于统计学，机器学习经常用于处理复杂的大型数据集（比如包含数百万张图像的数据集，每张图像又包含数万个像素），用经典的统计分析（比如贝叶斯分析）来处理这种数据集是不切实际的。\n",
    "\n",
    "深度学习是机器学习的一个分支领域：它是从数据中学习表示的一种新方法，强调从连续的层（layer）中进行学习，这些层对应于越来越有意义的表示。“深度学习”中的“深度”指的并不是利用这种方法所获取的更深层次的理解，而是指一系列连续的表示层。数据模型中包含多少层，这被称为模型的深度（depth）。\n",
    "\n",
    "这些分层表示是通过神经网络（neural network）的模型来学习得到的。神经网络这一术语来自于神经生物学，是从人们对大脑的理解中汲取灵感而形成的。神经网络的结构是逐层堆叠。深度学习算法就可以理解为学习数据表示的多级方法。\n",
    "\n",
    "这一领域的其他名称包括分层表示学习（layered representation learning）和层级表示学习（hierarchical representation learning）。现代深度学习通常包含数十个甚至上百个连续的表示层，这些表示层全都是从训练数据中自动学习的。\n",
    "\n",
    "机器学习，特别是深度学习，已经成为人工智能领域发展的主要技术驱动元素，促使该领域所使用的工具集出现大众化趋势。如今，只要具有基本的Python脚本技能，就可以从事高级的深度学习和人工智能研究。这主要得益于Theano及随后的TensorFlow的开发，以及Keras等用户友好型库的兴起。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习框架简介\n",
    "\n",
    "人工智能技术的研究者都需要写大量的重复的深度学习算法代码。为了提高工作效率，这些研究者就将这些代码写成了深度学习框架（framework）放到网上，供所有研究者一起使用。于是，网上就出现了不同的框架。随着时间的推移，一些深度学习框架被大量的人使用从而流行了起来，这其中就包括TensorFlow、Caffe、Keras、Torch7、MXNet、Leaf、Theano、DeepLearning4、Lasagne、Neon等。研究者们使用各种不同的框架来达到他们的研究目的，侧面印证出深度学习领域百花齐放。在开始深度学习项目之前，选择一个合适的框架是非常重要的，因为选择一个合适的框架能起到事半功倍的作用。\n",
    "\n",
    "Keras是其中一个较受欢迎的深度学习框架，可以方便地定义和训练几乎所有类型的深度学习模型。Keras在2015年初发布，并且很快就成为大量创业公司、在校生和研究人员转向该领域的首选深度学习解决方案。Keras具有以下重要特性：\n",
    "1. 相同的代码可以在CPU或GPU上无缝切换运行。\n",
    "2. 具有用户友好的API，便于快速开发深度学习模型的原型。\n",
    "3. 具有支持卷积网络（用于计算机视觉）、循环网络（用于序列处理）以及二者的任意组合。\n",
    "4. 支持任意的网络架构：多输入或多输出模型、层共享、模型共享等。这也就是说，Keras能够构建任意深度学习模型，无论是生成式对抗网络还是神经图灵机。\n",
    "5. Keras基于宽松的MIT许可证发布，这意味着可以在商业项目中免费使用它。它与所有版本的Python都兼容（截至2017年年中，从Python2.7到Python3.6都兼容）。\n",
    "\n",
    "目前Keras已有20多万个用户，既包括创业公司和大公司的学术研究人员和工程师，也包括研究生和业余爱好者。从 Google Trends 过去三年的统计数据可以看到，在全球范围内计算机科学领域，TensorFlow、Keras、PyTorch、Caffe、Theano 这五个框架在 Google 网页搜索的热度中，虽然TensorFlow一直处于统治地位，但是排名第二的Keras上升速度明显。目前，Google、Netflix、Uber、CERN以及上百家创业公司都在用Keras解决各种各样的问题。Keras还是机器学习竞赛网站Kaggle上的热门框架，最新的深度学习竞赛中，几乎所有的优胜者用的都是Keras模型。\n",
    "\n",
    "本书推荐选择Keras作为入门学习深度学习框架的另外原因，是因为它是一个模型级（model-level）的库，为开发深度学习模型提供了高层次的构建模块。它不处理张量操作、求微积分等基础的运算。相反，它依赖于一个专门的、高度优化的张量库来完成这些运算，这个张量库就是Keras的后端引擎（backend engine）。Keras没有选择单个张量库并将Keras实现与这个库绑定，而是以模块的方式处理这个问题。因此，几个不同的后端引擎都可以无缝嵌入到Keras中。\n",
    "目前，Keras有三个后端实现：TensorFlow后端、Theano后端和微软认知工具包（CNTK，Microsoft congnitive toolkit）后端。未来Keras可能会扩展到支持更多的深度学习引擎。例如，通过TensorFlow（或Theano、CNTK），Keras可以在CPU和GPU上无缝运行。在CPU上运行时，TensorFlow本身封装了一个基础的张量运算库，叫做Eigen；在GPU上运行时，TensorFlow封装了一个高度优化的深度学习运算库，叫做NVIDIA CUDA深度神经网络库（cuDNN）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习中的数学概念\n",
    "\n",
    "要理解深度学习，需要熟悉一些基础的数学概念。在当前较流行的深度学习框架中，几乎都使用“张量（tensor）”作为基本数据结构。张量这一概念对这一领域非常重要，其核心在于，它是一个数据容器。它包含的数据几乎总是数值数据，因此它是数字的容器。\n",
    "\n",
    "在几何代数中，张量是基于向量和矩阵的推广。张量的维度通常称为“轴（axis）”，张量轴的个数也叫作“阶（rank）”。仅包含一个数字的张量也称为标量，可视为零阶张量（或0D张量）；由数字组成的数组也称为向量，可视为一阶张量（或1D张量）；由向量组成的数组也称为矩阵，可视为二阶张量（或2D张量）。因此，标量张量有0个轴，向量张量只有一个轴，而矩阵张量有两个轴。\n",
    "\n",
    "将多个矩阵组合在一起，可以得到一个3D张量，也可以将其直观地理解为数字组成的立方体。将多个3D张量组合成一个数组，可以创建一个4D张量，以此类推。深度学习处理的一般是0D到4D的张量，但处理视频数据时可能会遇到5D张量。\n",
    "\n",
    "张量由以下三个关键属性来定义。\n",
    "\n",
    "1. **轴的个数（阶）**。例如，3D张量有3个轴，矩阵张量有2个轴。在Python中，通常叫作张量的ndim。\n",
    "2. **形状**。这是一个整数元组，表示张量沿每个轴的维度大小（元素个数）。在Python中，通常叫作张量的shape。\n",
    "3. **数据类型**。这是张量中所包含数据的类型，例如张量的类型可以是float32、unit8、float64等。在Python中，通常叫作dtype。\n",
    "\n",
    "为了具体说明，我们以Keras框架自带的数据集MNIS为例给予解释。首先加载MNIST数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们给出张量train_images的轴的个数，即ndim属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是它的形状，即shape属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是它的数据类型，即dtype属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，这里train_images是一个由8位整数组成的3D张量。更确切地说，它是60000个矩阵组成的数组，每个矩阵由28\\*28个整数组成。每个这样的矩阵都是一张灰度图像，元素取值范围为0~255。我们用Matplotlib库来显示这个3D张量中的第4个数字，如图4所示。\n",
    "\n",
    "在上面的例子中，我们使用语法train_images\\[i\\]来选择沿着第一个轴的特定数字。选择张量的特定元素叫作张量切片（tensor slicing）。下面看一下Numpy数组上的张量切片运算。下面的这个例子选择第10~100个数字（不包括第100个），并将其放在形状为(90, 28, 28)的数组中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#显示NMIST数据集中的样本\n",
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10: 100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有的计算机程序最终都可以简化为二进制输入上的一些二进制运算（AND、OR、NOR等），与此类似，深度学习学到的所有变换也都可以简化为数值数据张量上的一些张量运算（tensor operation）,例如加上张量、乘以张量等。由于篇幅所限，此处不再赘述。在后续章节，将以一个简单的例子加以阐述。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络剖析\n",
    "\n",
    "神经网络由四个核心组件构成，即层、网络、目标函数和优化器。可以将这四者的关系可视化。多个层连接在一起组成了网络，将输入数据映射为预测值。然后损失函数将这些预测值与目标进行比较，得到损失值，用于衡量网络预测值与预期结果的匹配程度。优化器使用这个损失值来更新网络的权重。\n",
    "\n",
    "### 层: 深度学习的基础组件\n",
    "神经网络的基础组件是层（layer）。层是一个数据处理模块，它接受一个或多个张量作为输入，并输出一个或多个张量。有些层是无状态的，但更常见的是层有状态的，即层的权重。权重是用随机梯度下降学到的一个或几个张量，这些张量一起组成了网络的知识。\n",
    "\n",
    "不同的层适用于不同的张量格式和不同类型的数据处理。例如，简单的向量数据存储在形状为(samples, features)的2D张量中，通常由紧密连接的层（densely connected）来处理。序列数据存储在形状为(samples,timesteps, features)的3D张量中，通常由循环层（recurrent layer）来处理。图像数据存储在4D张量中，通常由二维卷积层(Conv2D)来处理。\n",
    "\n",
    "在Keras中，构建深度学习模型就是将相互兼容的多个层拼接起来，以建立有用的数据变化流程。这里层兼容性（layer compatibility）具体指的是每一层只接受特定性状的输入张量，并返回特定形状的输出张量。看看下面的例子：\n",
    "\n",
    "    from keras import layers\n",
    "    \n",
    "    layer = layers.Dense(32, input_shape=(784,)) #有32个输出单元的密集层\n",
    "\n",
    "我们创建了一个层，只接受第一个维度大小为784的2D张量（第0轴是批量维度，其大小没有指定，因此可以任意取值）作为输入。这个层将返回一个张量，第一个维度的大小变成了32。\n",
    "\n",
    "因此，这个层后面只能连接一个接受32维向量作为输入的层。使用Keras时，你无需担心兼容性，因为向模型中添加的层都会自动匹配输入层的形状，例如下面这段代码。\n",
    "\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(32, input_shape=(784,)))\n",
    "    model.add(layers.Dense(32)\n",
    "    \n",
    "其中第二层没有输入形状（input_shape）的参数，相反，它可以自动推导出输入形状等于上一层的输出形状。\n",
    "\n",
    "### 模型：层构成的网络\n",
    "\n",
    "深度学习模型是层构成的有向无环图。最常见的实例是层的线性堆叠，将单一输入映射为单一输出。但是随着深入学习，你将接触到更多类型的网络拓扑结构。一些常见的网络拓扑结构如下：\n",
    "\n",
    "- 双分支（two-branch）网络\n",
    "- 多头（multihead）网络\n",
    "- Inception模块\n",
    "\n",
    "网络的拓扑结构定义了一个假设空间（hypothesis space）。选定了网络拓扑结构，也就意味着将可能性（假设空间）限定为一系列特定的张量计算，将输入数据映射为输出数据。然后，你需要为这些张量运算的权重张量找到一组合适的值。\n",
    "\n",
    "选择正确的网络架构更像是一门艺术而不是科学。虽然有一些最佳实践和原则，但只有动手实践才能让你成为合格的神经网络架构师。\n",
    "\n",
    "### 损失函数和优化器：配置学习过程的关键\n",
    "一旦确定了网络架构，你还需要选择以下两个参数。\n",
    "\n",
    "- 损失函数(目标函数)——在训练过程中需要将其最小化。它代能够衡量当前任务是否已经成功完成。\n",
    "- 优化器——决定如何基于损失函数对网络进行更新。它执行的是随机梯度下降（SGD）的某个变体。\n",
    "\n",
    "具有多个输出的神经网络可能具有多个损失函数（每个输出对应一个损失函数）。但是，梯度下降过程必须基于单个标量损失值。因此，对于具有多个损失函数的网络，需要将所有损失函数取平均，变为一个标量值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 典型的Keras工作流程\n",
    "\n",
    "典型的Keras工作流程如下：\n",
    "\n",
    "1. 定义训练数据：输入张量和目标张量；\n",
    "2. 定义层组成的网络（或模型），将输入映射到目标；\n",
    "3. 配置学习过程：选择损失函数、优化器和需要监控的指标；\n",
    "4. 调用模型的fit方法在训练数据上进行迭代。\n",
    "\n",
    "定义模型有两种方法：一种是使用Sequential类（仅用于层的线性堆叠，这是目前最常见的网络架构），另一种是函数式API（functional API，用于层组成的有向无环图，可以构建任意形式的架构）。如前所述，在本例中，利用Sequential类定义两层模型，具体代码如下：\n",
    "\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(32, input_shape=(784,)))\n",
    "    model.add(layers.Dense(32)\n",
    "\n",
    "配置学习过程是在编译这一步，用户需要指定模型使用的优化器和损失函数，以及训练过程中想要监控的指标。下面是单一损失函数的例子：\n",
    "\n",
    "    from keras import optimizers\n",
    "    \n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=0.001), \n",
    "                  loss='mse', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "最后，学习过程是通过fit()方法将输入数据的Numpy数组（和对应的目标数据）传入模型，代码如下：\n",
    "\n",
    "    model.fit(input_tensor, targe_tensor, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例：手写数字图像识别\n",
    "\n",
    "本节综合本章前面所讲的内容，基于Keras给出一个关于通过深度学习算法实现自动识别手写数字图像的完整实例。它使用Keras自带的MNIST手写数字图像数据集来学习如何对手写数字进行分类。MNIST数据集来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST)，包括60000张训练图片和10000张测试图片，划分到10个类别（0~9）。每张图片由28\\*28个像素点构成，每个像素点用一个介于0~255之间的灰度值表示。以下给出本示例的完整代码，主要流程实现的内容在程序注释中给予说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.2555 - acc: 0.925620s - loss: 1.1541 - a - ETA: 13s - loss - ETA: 10s - - E - ETA: - ETA: 3s - loss: 0.3122 - acc: 0.908 - ETA: 3s - ETA: 1s - loss: 0.2787 - acc: 0 - ETA: 1s - loss: 0.2746 - acc: 0 - ETA: 1s - loss: 0.2710 - acc:  - ETA: 0s - loss: 0.2659 - - ETA: 0s - loss: 0.2570 - acc: 0.9\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.1027 - acc: 0.969011s - loss: 0. - ETA: 7s - loss: 0.1095 - acc: 0. - ETA: 7s - loss: 0 - ETA: 6s - loss: 0.1074  - ETA: 5s - loss - ETA:\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0677 - acc: 0.97977s - loss: 0.0680 - ETA:  - ETA: 5s - loss: 0.0690 - acc: 0.979 - ETA: 5s - loss: 0.0688  - ETA: 5s - loss: 0 - ETA: 4s - loss: 0.0686 - acc: - ETA: 4s - loss: - ETA: 3s - loss: 0.0686 - acc:  - ETA: 2s - loss: 0.0685 - acc: 0 - ETA: 2 - ETA: 0s - loss: 0.0679 - acc: 0.979 - ETA: 0s - loss: 0.0680 - a\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0497 - acc: 0.9850 4s - loss: - ETA: 3s - loss: 0.0496 - acc: 0.985 - ETA: 3s - loss: 0.0\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0370 - acc: 0.9889 8s - loss: 0.0321 - acc: - ETA: 7s - loss: 0.0330 - a - ETA: 7s - loss: 0.0348 - ac - ETA: 7s - loss: 0 - E - ETA: 3s - loss: 0.0378 - acc: 0.988 - ETA: 3s - loss: 0.0379 - - ETA: 0s - loss: 0.0374 - acc: 0.98 - ETA: 0s - loss: 0.0373 - a\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0287 - acc: 0.99148s - loss: 0.02 - ETA: 7s - loss: 0.0281 - acc: - ETA: 7s - loss: 0.02 - ETA: 5 - ETA: 3s - loss: 0.029 - ETA: 2s - loss: 0.0285 - acc: 0.991 - ETA: 2s  - ETA: 1s - loss\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0225 - acc: 0.993311s - loss: 0.0191 - - ETA: 10s - loss: 0.0194 - acc: 0.99 - ETA: 10s - loss: 0.0192 - acc:  -  - ETA: 5s - loss: 0.0201  - ETA: 4s - loss: 0.0208 - acc: 0.99 - ETA: 4 - ETA: 2\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0164 - acc: 0.99532s - loss: 0.0157 - acc:  - ETA: 2s - loss: 0.0162 - acc: 0 - ETA: 2s - loss: 0.0 - ETA: 1s - loss: 0.0161 -  - ETA: 0s - loss: 0.0162 -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28b767762b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 代码清单：使用Keras进行手写字体识别（MNIST数据集）\n",
    "# 加载Keras中的MNIST数据集\n",
    "# MNIST数据集预先加载在Keras库中，其中包括4个Numpy数组。train_images和train_labels组成了训练集（training set），模型将从这些数据中进行学习。然后在测试集（test set，即test_images和test_labels）上对模型进行测试。\n",
    "# 图像被编码为Numpy数组，而标签是数字数组，取值范围为0~9。图像和标签一一对应。\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# 构建网络\n",
    "# 所构建的网络包含了两个层，它们是密集连接（也叫全连接）的神经层。第二层（也是最后一层）是一个10路softmax层，\n",
    "#它将返回一个由10个概率值（总和为1）组成的数组。每个概率值表示当前数字图像属于10个数字类别中某一个的概率。\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 编译\n",
    "# 要想训练网络，还需要选择编译（compile）步骤的三个参数：\n",
    "# 损失函数（loss function）：网络如何衡量在训练数据上的性能，即网络如何朝着正确的方向前进。\n",
    "# 优化器（optimizer）：基于训练数据和损失函数来更新网络的机制。\n",
    "# 在训练和测试过程中需要监控的指标（metric）：本例只关心精度，即正确分类的图像所占的比例。\n",
    "network.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# 准备图像数据\n",
    "# 在开始训练之前，我们将对数据进行预处理，将其变换为网络要求的形状，并缩放到所有值都在[0, 1]区间。比如，之前训练图像保存在一个uint8类型的数组中，其形状为(60000, 28, 28)，取值区间为[0, 255]。我们需要将其变换为一个float32数组，其形状为(60000, 28 * 28O), 取值范围为0~1。\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# 准备标签\n",
    "# train_labels和test_labels是手写数字的标签，写的是数字几，标签就是几（从0~9）。我们需要把标签转换成10阶向量里面的元素都是0或1.比如标签为3，就把标签转换为向量(0, 0, 0, 1, 0, 0, 0, 0, 0, 0)。\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# 调用fit方法训练网络\n",
    "#其中，epochs表示训练的次数，batch_size表示每个训练块包含的数据个数。\n",
    "network.fit(train_images, train_labels, epochs=8, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "训练过程中显示了两个数字：一个是网络在训练数据上的损失（loss），另一个是网络在训练数据上的精度（acc）。通过执行上面的程序，可以发现在训练集上达到了0.9951的精度。\n",
    "\n",
    "执行下面代码，以检查模型在测试集上的性能。 \n",
    "     \n",
    "    >>>test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "    >>>print('test_acc:', test_acc)\n",
    "    test_acc: 0.9803\n",
    "    \n",
    "可以看到，测试集精度为0.9803，比训练集要低。训练精度和测试精度之间的这种差距是过拟合（overfit）造成的。过拟合是指机器学习模型在新的数据上的性能比在训练数据上要差，可以通过正则化或数据增强等手段加以解决。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 107us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('test_acc:', 0.9818)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本章小结\n",
    "1. 人工智能是一个综合领域，包括机器学习、深度学习，以及其他不涉及学习的方法。\n",
    "2. 利用机器学习，人们输入的是数据和从这些数据中预期得到的答案，系统输出的是规则。这些规则可应用于新的数据，并使计算机自主生成答案。\n",
    "3. 深度学习是机器学习的一个分支领域：它是从数据中学习表示的一种新方法，强调从连续的层（layer）中进行学习，这些层对应于越来越有意义的表示。这些分层表示是通过神经网络（neural network）的模型来学习得到的。\n",
    "4. Keras是一个模型级（model-level）的库，为开发深度学习模型提供了高层次的构建模块。目前，Keras有三个后端实现：TensorFlow后端、Theano后端和微软认知工具包（CNTK，Microsoft congnitive toolkit）后端。\n",
    "5. 在当前较流行的深度学习框架中，几乎都使用“张量（tensor）”作为基本数据结构，可以理解为是一个数据容器。张量由阶数、形状和数据类型三个关键属性来定义。\n",
    "6. 神经网络由四个核心组件构成，即层、网络、目标函数和优化器。多个层连接在一起组成了网络，将输入数据映射为预测值。然后损失函数将这些预测值与目标进行比较，得到损失值，用于衡量网络预测值与预期结果的匹配程度。优化器使用这个损失值来更新网络的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": "15",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
